{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the processed data and Split it into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# performance matrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path of processed data\n",
    "processed_data_path = os.path.join(os.path.pardir, 'data', 'processed')\n",
    "df_data_path = os.path.join(processed_data_path, 'processed_Data_Employee-Attrition.csv')\n",
    "df = pd.read_csv(df_data_path, index_col='EmployeeNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>JobRole_Laboratory Technician</th>\n",
       "      <th>JobRole_Manager</th>\n",
       "      <th>JobRole_Manufacturing Director</th>\n",
       "      <th>JobRole_Research Director</th>\n",
       "      <th>JobRole_Research Scientist</th>\n",
       "      <th>JobRole_Sales Executive</th>\n",
       "      <th>JobRole_Sales Representative</th>\n",
       "      <th>MaritalStatus_Divorced</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Attrition  Age  DailyRate  DistanceFromHome  Education  \\\n",
       "EmployeeNumber                                                           \n",
       "1                       1   41       1102                 1          2   \n",
       "2                       0   49        279                 8          1   \n",
       "4                       1   37       1373                 2          2   \n",
       "5                       0   33       1392                 3          4   \n",
       "7                       0   27        591                 2          1   \n",
       "\n",
       "                EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  \\\n",
       "EmployeeNumber                                                                \n",
       "1                                     2       0          94               3   \n",
       "2                                     3       1          61               2   \n",
       "4                                     4       1          92               2   \n",
       "5                                     4       0          56               3   \n",
       "7                                     1       1          40               3   \n",
       "\n",
       "                JobLevel  ...  JobRole_Laboratory Technician  JobRole_Manager  \\\n",
       "EmployeeNumber            ...                                                   \n",
       "1                      2  ...                              0                0   \n",
       "2                      2  ...                              0                0   \n",
       "4                      1  ...                              1                0   \n",
       "5                      1  ...                              0                0   \n",
       "7                      1  ...                              1                0   \n",
       "\n",
       "                JobRole_Manufacturing Director  JobRole_Research Director  \\\n",
       "EmployeeNumber                                                              \n",
       "1                                            0                          0   \n",
       "2                                            0                          0   \n",
       "4                                            0                          0   \n",
       "5                                            0                          0   \n",
       "7                                            0                          0   \n",
       "\n",
       "                JobRole_Research Scientist  JobRole_Sales Executive  \\\n",
       "EmployeeNumber                                                        \n",
       "1                                        0                        1   \n",
       "2                                        1                        0   \n",
       "4                                        0                        0   \n",
       "5                                        1                        0   \n",
       "7                                        0                        0   \n",
       "\n",
       "                JobRole_Sales Representative  MaritalStatus_Divorced  \\\n",
       "EmployeeNumber                                                         \n",
       "1                                          0                       0   \n",
       "2                                          0                       0   \n",
       "4                                          0                       0   \n",
       "5                                          0                       0   \n",
       "7                                          0                       0   \n",
       "\n",
       "                MaritalStatus_Married  MaritalStatus_Single  \n",
       "EmployeeNumber                                               \n",
       "1                                   0                     1  \n",
       "2                                   1                     0  \n",
       "4                                   0                     1  \n",
       "5                                   1                     0  \n",
       "7                                   1                     0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#as_matrix creates a matrix and astype change all the value to type float\n",
    "#ravel is numpy function which creates a one dimention array with values from columns specified. \n",
    "\n",
    "X = df.loc[:,'Age':].as_matrix().astype('float')\n",
    "y = df['Attrition'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1470, 48) (1470,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 48) (1029,)\n",
      "(441, 48) (441,)\n"
     ]
    }
   ],
   "source": [
    "#split the data into two parts training and testing\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Attrition in train : 0.16055846422338568\n",
      "Mean Attirtion in test : 0.16358024691358025\n"
     ]
    }
   ],
   "source": [
    "# Average Attrition in train and test \n",
    "print(f\"Mean Attrition in train : {np.mean(y_train)}\")\n",
    "print(f\"Mean Attirtion in test : {np.mean(y_test)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    " - ***First observation is Mean Attrition in train and test data are almost equal that shows that the data is split properly. We do not want too much difference in mean in other words We want positive cases to be distributed evenly in both trainig and test data.***\n",
    "\n",
    " - ***Second observation is almost of 16% of Attrition values are 1 rest are 0. We can use this information to build our base line model.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    " - **DummyClassifier** - Strategy to use to generate predictions.\n",
    "\n",
    "      - “stratified”: generates predictions by respecting the training set’s class distribution.\n",
    "      - “most_frequent”: always predicts the most frequent label in the training set.\n",
    "      - “prior”: always predicts the class that maximizes the class prior (like “most_frequent”) and predict_proba          returns the class prior.\n",
    "      - “uniform”: generates predictions uniformly at random.\n",
    "      - “constant”: always predicts a constant label that is provided by the user. This is useful for metrics that          evaluate a non-majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base line Model with the value of most_requent\n",
    "model_dummy = DummyClassifier(strategy='most_frequent', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit your training data to the model to learn\n",
    "model_dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for baseline Model: 0.8412698412698413\n"
     ]
    }
   ],
   "source": [
    "# provide your test values it will compare your predicted value to the actual value in test data set and provide score. \n",
    "print(f\"Score for baseline Model: {model_dummy.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance matrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for baseline model: 0.8412698412698413\n",
      "Precision for baseline model: 0.0\n",
      "Recall for baseline model: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#print Accuracy, Precission and Recall\n",
    "print(f\"Accurancy for baseline model: {accuracy_score(y_test, model_dummy.predict(X_test))}\")\n",
    "print(f\"Precision for baseline model: {precision_score(y_test, model_dummy.predict(X_test))}\")\n",
    "print(f\"Recall for baseline model: {recall_score(y_test, model_dummy.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accuracy** - Compare predicted output with actual output. \n",
    "     - Accuracy = Correct / Total Count\n",
    "     \n",
    " - **Precision & Recall**: \n",
    " \n",
    " **Confution Metrix**\n",
    " \n",
    "| | Predicted Negtive  |  Predicted Possitive |\n",
    "|:---:|:---:|:---:|\n",
    "|Actual Negative | True Negative (TN) | False Positive (FP)  |\n",
    "|Actual Possitve | False Negative (FN)| True Positive (TP)   |\n",
    "  \n",
    "   **Precision**: What fraction of positive predictions are correct?\n",
    "           TP / Total Positive Prediction = TP / TP + FP\n",
    "           \n",
    "   **Recall** : What fraction of positive cases you predicted correctly?\n",
    "           TP / Total Positive Cases = TP / TP + FN\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_1 = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765804155866977"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cross_val_score(model_lr_1, X_train, y_train, cv=10)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Logistic Regression Model: 0.8843537414965986\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score for Logistic Regression Model: {model_lr_1.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for LR model: 0.8843537414965986\n",
      "Confusion Matrix for LR model: [[364   7]\n",
      " [ 44  26]]\n",
      "Precision for LR model: 0.7878787878787878\n",
      "Recall for LR model: 0.37142857142857144\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics Test Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for LR model: {accuracy_score(y_test, model_lr_1.predict(X_test))}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for LR model: {confusion_matrix(y_test, model_lr_1.predict(X_test))}\")\n",
    "# Precision\n",
    "print(f\"Precision for LR model: {precision_score(y_test, model_lr_1.predict(X_test))}\")\n",
    "# Recall\n",
    "print(f\"Recall for LR model: {recall_score(y_test, model_lr_1.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Optimization using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1', 'l2']}\n",
    "clf = GridSearchCV(model_lr_1, param_grid=parameters, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8736637512147716\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Score: {clf.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for logistic regression version 2: 0.891156462585034\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(f\"Score for logistic regression version 2: {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression Score 0.8765432098765432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sc = StandardScaler()\n",
    "X_train_std = x_sc.fit_transform(X_train)\n",
    "X_test_std = x_sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt_1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "model_dt_1.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_dt_1.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Decision Tree Classifier Model: 0.7664399092970522\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score for Decision Tree Classifier Model: {model_dt_1.score(X_test_std, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[317  54]\n",
      " [ 49  21]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"criterion\":(\"gini\", \"entropy\"), \n",
    "          \"splitter\":(\"best\", \"random\"), \n",
    "          \"max_depth\":(list(range(1, 20))), \n",
    "          \"min_samples_split\":[2, 3, 4], \n",
    "          \"min_samples_leaf\":list(range(1, 20)), \n",
    "          }\n",
    "\n",
    "grid_search_cv = GridSearchCV(model_dt_1, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 556 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 12996 out of 12996 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None, max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=0,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17, 18, 19],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                              12, 13, 14, 15, 16, 17, 18, 19],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'splitter': ('best', 'random')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_search_cv.predict(X_train_std)\n",
    "y_test_pred = grid_search_cv.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 0.8658892128279884\n",
      "Confusion Matrix for DT model: [[827  35]\n",
      " [103  64]]\n",
      "Precision for DT model: 0.6464646464646465\n",
      "Recall for DT model: 0.38323353293413176\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for DT model: {accuracy_score(y_train, y_train_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for DT model: {confusion_matrix(y_train, y_train_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for DT model: {precision_score(y_train, y_train_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for DT model: {recall_score(y_train, y_train_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 0.8594104308390023\n",
      "Confusion Matrix for DT model: [[356  15]\n",
      " [ 47  23]]\n",
      "Precision for DT model: 0.6052631578947368\n",
      "Recall for DT model: 0.32857142857142857\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for DT model: {accuracy_score(y_test, y_test_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for DT model: {confusion_matrix(y_test, y_test_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for DT model: {precision_score(y_test, y_test_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for DT model: {recall_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test \t\t y_test_pred\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 1\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 1\n",
      "0 \t\t\t 0\n",
      "0 \t\t\t 0\n",
      "1 \t\t\t 0\n"
     ]
    }
   ],
   "source": [
    "print('y_test \\t\\t y_test_pred')\n",
    "for n,g in zip(y_test,y_test_pred):\n",
    "    print(f\"{n} \\t\\t\\t {g}\")\n",
    "\n",
    "\n",
    "# print(f\"{y_test} \\n {y_test_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "bag_clf = BaggingClassifier(base_estimator=model, n_estimators=100, bootstrap=True, \n",
    "                                   n_jobs=-1, oob_score=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=42,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=True,\n",
       "                  random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = bag_clf.predict(X_train)\n",
    "y_test_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 1.0\n",
      "Confusion Matrix for DT model: [[862   0]\n",
      " [  0 167]]\n",
      "Precision for DT model: 1.0\n",
      "Recall for DT model: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for Bagging model: {accuracy_score(y_train, y_train_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for Bagging model: {confusion_matrix(y_train, y_train_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for Bagging model: {precision_score(y_train, y_train_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for Bagging model: {recall_score(y_train, y_train_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 0.8571428571428571\n",
      "Confusion Matrix for DT model: [[361  10]\n",
      " [ 53  17]]\n",
      "Precision for DT model: 0.6296296296296297\n",
      "Recall for DT model: 0.24285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for Bagging model: {accuracy_score(y_test, y_test_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for Bagging model: {confusion_matrix(y_test, y_test_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for Bagging model: {precision_score(y_test, y_test_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for Bagging model: {recall_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[3, None], 'min_samples_split':[2, 3, 10], \n",
    "              'min_samples_leaf':[1, 3, 10], 'bootstrap':[True, False], \n",
    "              'criterion':[\"gini\", \"entropy\"]}\n",
    "\n",
    "model_rf_1 = RandomForestClassifier(random_state=42, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rand_forest = GridSearchCV(model_rf_1, param_grid, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3, iid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=1000, n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, None], 'min_samples_leaf': [1, 3, 10],\n",
       "                         'min_samples_split': [2, 3, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rand_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = bag_clf.predict(X_train)\n",
    "y_test_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 1.0\n",
      "Confusion Matrix for DT model: [[862   0]\n",
      " [  0 167]]\n",
      "Precision for DT model: 1.0\n",
      "Recall for DT model: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for Random Forest model: {accuracy_score(y_train, y_train_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for Random Forest model: {confusion_matrix(y_train, y_train_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for Random Forest model: {precision_score(y_train, y_train_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for Random Forest model: {recall_score(y_train, y_train_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 0.8571428571428571\n",
      "Confusion Matrix for DT model: [[361  10]\n",
      " [ 53  17]]\n",
      "Precision for DT model: 0.6296296296296297\n",
      "Recall for DT model: 0.24285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for Random Forest model: {accuracy_score(y_test, y_test_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix forRandom Forest model: {confusion_matrix(y_test, y_test_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision forRandom Forest model: {precision_score(y_test, y_test_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for Random Forest model: {recall_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xt_1 = ExtraTreesClassifier(random_state=42, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[3, None], 'min_samples_split':[2, 3, 10], \n",
    "              'min_samples_leaf':[1, 3, 10], 'bootstrap':[True, False], \n",
    "              'criterion':[\"gini\", \"entropy\"]}\n",
    "\n",
    "grid_rand_forest = GridSearchCV(model_xt_1, param_grid, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3, iid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None,\n",
       "                                            criterion='gini', max_depth=None,\n",
       "                                            max_features='auto',\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=1000, n_jobs=None,\n",
       "                                            oob_score=False, random_state=42,\n",
       "                                            verbose=0, warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, None], 'min_samples_leaf': [1, 3, 10],\n",
       "                         'min_samples_split': [2, 3, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rand_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_rand_forest.predict(X_train)\n",
    "y_test_pred = grid_rand_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 1.0\n",
      "Confusion Matrix for DT model: [[862   0]\n",
      " [  0 167]]\n",
      "Precision for DT model: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for Extra Tree Ensemble model: {accuracy_score(y_train, y_train_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for Extra Tree Ensemble model: {confusion_matrix(y_train, y_train_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for Extra Tree Ensemble model: {precision_score(y_train, y_train_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for Extra Tree Ensemble model: {recall_score(y_train, y_train_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for DT model: 0.8639455782312925\n",
      "Confusion Matrix for DT model: [[368   3]\n",
      " [ 57  13]]\n",
      "Precision for DT model: 0.8125\n",
      "Recall for DT model: 0.18571428571428572\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for Extra Tree Ensemble model: {accuracy_score(y_test, y_test_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for Extra Tree Ensemble model: {confusion_matrix(y_test, y_test_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for Extra Tree Ensemble model: {precision_score(y_test, y_test_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for Extra Tree Ensemble model: {recall_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost / Adaptative Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_frst_clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                       min_samples_leaf=1, min_samples_split=3,\n",
    "                                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
    "                                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
    "                                       warm_start=False)\n",
    "\n",
    "model_adb_1 = AdaBoostClassifier(rand_frst_clf, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=None,\n",
       "                                                         max_features='auto',\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=3,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         n_estimators=1000,\n",
       "                                                         n_jobs=None,\n",
       "                                                         oob_score=False,\n",
       "                                                         random_state=42,\n",
       "                                                         verbose=0,\n",
       "                                                         warm_start=False),\n",
       "                   learning_rate=1.0, n_estimators=1000, random_state=None)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adb_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model_adb_1.predict(X_train)\n",
    "y_test_pred = model_adb_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for ADABoost model: 1.0\n",
      "Confusion Matrix for ADABoost model: [[862   0]\n",
      " [  0 167]]\n",
      "Precision for ADABOOST model: 1.0\n",
      "Recall for ADABOOST model: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics training Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for ADABoost model: {accuracy_score(y_train, y_train_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for ADABoost model: {confusion_matrix(y_train, y_train_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for ADABOOST model: {precision_score(y_train, y_train_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for ADABOOST model: {recall_score(y_train, y_train_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for ADABoost model: 0.8639455782312925\n",
      "Confusion Matrix for ADABoost model: [[370   1]\n",
      " [ 59  11]]\n",
      "Precision for ADABoost model: 0.9166666666666666\n",
      "Recall for ADABoost model: 0.15714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics Testing Data\n",
    "# Accuracy\n",
    "print(f\"Accurancy for ADABoost model: {accuracy_score(y_test, y_test_pred)}\")\n",
    "# Confusion matrix\n",
    "print(f\"Confusion Matrix for ADABoost model: {confusion_matrix(y_test, y_test_pred)}\")\n",
    "# Precision\n",
    "print(f\"Precision for ADABoost model: {precision_score(y_test, y_test_pred)}\")\n",
    "# Recall\n",
    "print(f\"Recall for ADABoost model: {recall_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Standardisation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.9999999999999998)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:,0].min(), X_train_scaled[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.9999999999999998)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[:,0].min(), X_test_scaled[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(X, y):\n",
    "    model_lr = LogisticRegression(random_state=0)\n",
    "    parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1', 'l2']}\n",
    "    clf = GridSearchCV(model_lr, param_grid=parameters, cv=3)\n",
    "    clf.fit(X, y) \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8726919339164237"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = createModel(X_train_scaled, y_train)\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for logistic regression version 2: 0.8956916099773242\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(f\"Score for logistic regression version 2: {clf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Persistense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the file path\n",
    "model_file_path = os.path.join(os.path.pardir, 'models', 'lr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the files to write in write mode, wb is to write in binary format\n",
    "model_file_pickle = open(model_file_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persist the model\n",
    "pickle.dump(clf, model_file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "model_file_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the persistense file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the files in read mode\n",
    "model_file_pickle = open(model_file_path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "clf_loaded = pickle.load(model_file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the files\n",
    "model_file_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=0, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for persisted logistic regression : 0.8956916099773242\n"
     ]
    }
   ],
   "source": [
    "print(f\"score for persisted logistic regression : {clf_loaded.score(X_test_scaled, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
